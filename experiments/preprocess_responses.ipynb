{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dccd5a99",
   "metadata": {},
   "source": [
    "# LTL Tutor Response Pre-processing\n",
    "\n",
    "This notebook pre-processes `ltl-tutor-responses.csv` to:\n",
    "1. Parse `question_options` JSON and expand each option into its own row\n",
    "2. Extract a **seed formula** per question (the ground-truth LTL formula, regardless of question type)\n",
    "3. Normalize seed formulas using `parse_ltl_string` from `ltlnode`\n",
    "4. Add a **chosen option** column (correct answer or the misconception-matching distractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f969d10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC_DIR: /Users/siddharthaprasad/Desktop/LTLTutor/src\n",
      "parse_ltl_string imported OK\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Make src/ importable so we can use parse_ltl_string\n",
    "SRC_DIR = os.path.abspath(os.path.join('..', 'src'))\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "from ltlnode import parse_ltl_string\n",
    "\n",
    "print('SRC_DIR:', SRC_DIR)\n",
    "print('parse_ltl_string imported OK')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c375d",
   "metadata": {},
   "source": [
    "## 1. Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceee348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5,786 rows\n",
      "Columns: ['id', 'user_id', 'timestamp', 'misconception', 'question_text', 'question_options', 'correct_answer', 'question_type', 'mp_class', 'exercise', 'course']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>misconception</th>\n",
       "      <th>question_text</th>\n",
       "      <th>question_options</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>mp_class</th>\n",
       "      <th>exercise</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>anon-user-FIE5Vl</td>\n",
       "      <td>2024-06-27 18:46:16.631438</td>\n",
       "      <td>MisconceptionCode.OtherImplicit</td>\n",
       "      <td>(q &lt;-&gt; t) \\n q &amp; ! t;cycle{t &amp; !q;t &amp; !q}</td>\n",
       "      <td>[{\"value\": \"Yes\", \"misconceptions\": \"['Misconc...</td>\n",
       "      <td>False</td>\n",
       "      <td>trace_satisfaction_yn</td>\n",
       "      <td>guarantee safety</td>\n",
       "      <td>Exercise</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>anon-user-FIE5Vl</td>\n",
       "      <td>2024-06-27 18:46:19.712717</td>\n",
       "      <td>MisconceptionCode.OtherImplicit</td>\n",
       "      <td>(G (q &lt;-&gt; (X t)))</td>\n",
       "      <td>[{\"value\": \"! q &amp; t;! q &amp; ! t;t &amp; !q;cycle{!t ...</td>\n",
       "      <td>False</td>\n",
       "      <td>trace_satisfaction_mc</td>\n",
       "      <td>safety</td>\n",
       "      <td>Exercise</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>anon-user-xYuKsl</td>\n",
       "      <td>2024-06-27 23:39:53.86804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eventually, if 'b' holds, then globally, 'c' h...</td>\n",
       "      <td>[{\"value\": \"(G (b -&gt; (G c)))\", \"misconceptions...</td>\n",
       "      <td>True</td>\n",
       "      <td>english_to_ltl</td>\n",
       "      <td>persistence</td>\n",
       "      <td>Exercise contemplation-hawthorns</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           user_id                   timestamp  \\\n",
       "0   1  anon-user-FIE5Vl  2024-06-27 18:46:16.631438   \n",
       "1   2  anon-user-FIE5Vl  2024-06-27 18:46:19.712717   \n",
       "2   3  anon-user-xYuKsl   2024-06-27 23:39:53.86804   \n",
       "\n",
       "                     misconception  \\\n",
       "0  MisconceptionCode.OtherImplicit   \n",
       "1  MisconceptionCode.OtherImplicit   \n",
       "2                              NaN   \n",
       "\n",
       "                                       question_text  \\\n",
       "0          (q <-> t) \\n q & ! t;cycle{t & !q;t & !q}   \n",
       "1                                  (G (q <-> (X t)))   \n",
       "2  eventually, if 'b' holds, then globally, 'c' h...   \n",
       "\n",
       "                                    question_options  correct_answer  \\\n",
       "0  [{\"value\": \"Yes\", \"misconceptions\": \"['Misconc...           False   \n",
       "1  [{\"value\": \"! q & t;! q & ! t;t & !q;cycle{!t ...           False   \n",
       "2  [{\"value\": \"(G (b -> (G c)))\", \"misconceptions...            True   \n",
       "\n",
       "           question_type          mp_class                          exercise  \\\n",
       "0  trace_satisfaction_yn  guarantee safety                          Exercise   \n",
       "1  trace_satisfaction_mc            safety                          Exercise   \n",
       "2         english_to_ltl       persistence  Exercise contemplation-hawthorns   \n",
       "\n",
       "  course  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAW_CSV = os.path.join('ltl-tutor-responses.csv')\n",
    "df_raw = pd.read_csv(RAW_CSV)\n",
    "print(f\"Loaded {len(df_raw):,} rows\")\n",
    "print(\"Columns:\", list(df_raw.columns))\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7fe0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_type\n",
      "english_to_ltl           2270\n",
      "trace_satisfaction_mc    1807\n",
      "trace_satisfaction_yn    1709\n",
      "Name: count, dtype: int64\n",
      "\n",
      "correct_answer distribution:\n",
      "correct_answer\n",
      "True     4467\n",
      "False    1319\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_raw['question_type'].value_counts())\n",
    "print()\n",
    "print(\"correct_answer distribution:\")\n",
    "print(df_raw['correct_answer'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad41311",
   "metadata": {},
   "source": [
    "# 1.5 Remove Those Questions that are from the robotrain exercise\n",
    "\n",
    "Filter out rows where the exercise is `robotrain-entry` or `robotrain-exit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56379fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out robotrain exercises\n",
    "df_raw = df_raw[~df_raw['exercise'].isin(['robotrain-entry', 'robotrain-exit'])].reset_index(drop=True)\n",
    "print(f\"After filtering robotrain exercises: {len(df_raw):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbd7fd",
   "metadata": {},
   "source": [
    "## 2. Parse `question_options` and expand into one row per option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4790777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded to 19,894 rows (one per option)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>misconception</th>\n",
       "      <th>question_text</th>\n",
       "      <th>question_options</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>mp_class</th>\n",
       "      <th>exercise</th>\n",
       "      <th>course</th>\n",
       "      <th>option_value</th>\n",
       "      <th>option_misconceptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>anon-user-FIE5Vl</td>\n",
       "      <td>2024-06-27 18:46:16.631438</td>\n",
       "      <td>MisconceptionCode.OtherImplicit</td>\n",
       "      <td>(q &lt;-&gt; t) \\n q &amp; ! t;cycle{t &amp; !q;t &amp; !q}</td>\n",
       "      <td>[{\"value\": \"Yes\", \"misconceptions\": \"['Misconc...</td>\n",
       "      <td>False</td>\n",
       "      <td>trace_satisfaction_yn</td>\n",
       "      <td>guarantee safety</td>\n",
       "      <td>Exercise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>[MisconceptionCode.OtherImplicit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>anon-user-FIE5Vl</td>\n",
       "      <td>2024-06-27 18:46:16.631438</td>\n",
       "      <td>MisconceptionCode.OtherImplicit</td>\n",
       "      <td>(q &lt;-&gt; t) \\n q &amp; ! t;cycle{t &amp; !q;t &amp; !q}</td>\n",
       "      <td>[{\"value\": \"Yes\", \"misconceptions\": \"['Misconc...</td>\n",
       "      <td>False</td>\n",
       "      <td>trace_satisfaction_yn</td>\n",
       "      <td>guarantee safety</td>\n",
       "      <td>Exercise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>anon-user-FIE5Vl</td>\n",
       "      <td>2024-06-27 18:46:19.712717</td>\n",
       "      <td>MisconceptionCode.OtherImplicit</td>\n",
       "      <td>(G (q &lt;-&gt; (X t)))</td>\n",
       "      <td>[{\"value\": \"! q &amp; t;! q &amp; ! t;t &amp; !q;cycle{!t ...</td>\n",
       "      <td>False</td>\n",
       "      <td>trace_satisfaction_mc</td>\n",
       "      <td>safety</td>\n",
       "      <td>Exercise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>! q &amp; t;! q &amp; ! t;t &amp; !q;cycle{!t &amp; q;!t &amp; q}</td>\n",
       "      <td>[MisconceptionCode.BadStateQuantification]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>anon-user-FIE5Vl</td>\n",
       "      <td>2024-06-27 18:46:19.712717</td>\n",
       "      <td>MisconceptionCode.OtherImplicit</td>\n",
       "      <td>(G (q &lt;-&gt; (X t)))</td>\n",
       "      <td>[{\"value\": \"! q &amp; t;! q &amp; ! t;t &amp; !q;cycle{!t ...</td>\n",
       "      <td>False</td>\n",
       "      <td>trace_satisfaction_mc</td>\n",
       "      <td>safety</td>\n",
       "      <td>Exercise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q &amp; ! t;q &amp; ! t;cycle{q &amp; t;q &amp; ! t;q &amp; t}</td>\n",
       "      <td>[MisconceptionCode.OtherImplicit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>anon-user-FIE5Vl</td>\n",
       "      <td>2024-06-27 18:46:19.712717</td>\n",
       "      <td>MisconceptionCode.OtherImplicit</td>\n",
       "      <td>(G (q &lt;-&gt; (X t)))</td>\n",
       "      <td>[{\"value\": \"! q &amp; t;! q &amp; ! t;t &amp; !q;cycle{!t ...</td>\n",
       "      <td>False</td>\n",
       "      <td>trace_satisfaction_mc</td>\n",
       "      <td>safety</td>\n",
       "      <td>Exercise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q &amp; !t;! q &amp; t;t &amp; !q;cycle{t &amp; !q;t &amp; !q}</td>\n",
       "      <td>[MisconceptionCode.ImplicitG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>anon-user-FIE5Vl</td>\n",
       "      <td>2024-06-27 18:46:19.712717</td>\n",
       "      <td>MisconceptionCode.OtherImplicit</td>\n",
       "      <td>(G (q &lt;-&gt; (X t)))</td>\n",
       "      <td>[{\"value\": \"! q &amp; t;! q &amp; ! t;t &amp; !q;cycle{!t ...</td>\n",
       "      <td>False</td>\n",
       "      <td>trace_satisfaction_mc</td>\n",
       "      <td>safety</td>\n",
       "      <td>Exercise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q &amp; t;cycle{q &amp; t;q &amp; t}</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           user_id                   timestamp  \\\n",
       "0   1  anon-user-FIE5Vl  2024-06-27 18:46:16.631438   \n",
       "1   1  anon-user-FIE5Vl  2024-06-27 18:46:16.631438   \n",
       "2   2  anon-user-FIE5Vl  2024-06-27 18:46:19.712717   \n",
       "3   2  anon-user-FIE5Vl  2024-06-27 18:46:19.712717   \n",
       "4   2  anon-user-FIE5Vl  2024-06-27 18:46:19.712717   \n",
       "5   2  anon-user-FIE5Vl  2024-06-27 18:46:19.712717   \n",
       "\n",
       "                     misconception  \\\n",
       "0  MisconceptionCode.OtherImplicit   \n",
       "1  MisconceptionCode.OtherImplicit   \n",
       "2  MisconceptionCode.OtherImplicit   \n",
       "3  MisconceptionCode.OtherImplicit   \n",
       "4  MisconceptionCode.OtherImplicit   \n",
       "5  MisconceptionCode.OtherImplicit   \n",
       "\n",
       "                                question_text  \\\n",
       "0   (q <-> t) \\n q & ! t;cycle{t & !q;t & !q}   \n",
       "1   (q <-> t) \\n q & ! t;cycle{t & !q;t & !q}   \n",
       "2                           (G (q <-> (X t)))   \n",
       "3                           (G (q <-> (X t)))   \n",
       "4                           (G (q <-> (X t)))   \n",
       "5                           (G (q <-> (X t)))   \n",
       "\n",
       "                                    question_options  correct_answer  \\\n",
       "0  [{\"value\": \"Yes\", \"misconceptions\": \"['Misconc...           False   \n",
       "1  [{\"value\": \"Yes\", \"misconceptions\": \"['Misconc...           False   \n",
       "2  [{\"value\": \"! q & t;! q & ! t;t & !q;cycle{!t ...           False   \n",
       "3  [{\"value\": \"! q & t;! q & ! t;t & !q;cycle{!t ...           False   \n",
       "4  [{\"value\": \"! q & t;! q & ! t;t & !q;cycle{!t ...           False   \n",
       "5  [{\"value\": \"! q & t;! q & ! t;t & !q;cycle{!t ...           False   \n",
       "\n",
       "           question_type          mp_class  exercise course  \\\n",
       "0  trace_satisfaction_yn  guarantee safety  Exercise    NaN   \n",
       "1  trace_satisfaction_yn  guarantee safety  Exercise    NaN   \n",
       "2  trace_satisfaction_mc            safety  Exercise    NaN   \n",
       "3  trace_satisfaction_mc            safety  Exercise    NaN   \n",
       "4  trace_satisfaction_mc            safety  Exercise    NaN   \n",
       "5  trace_satisfaction_mc            safety  Exercise    NaN   \n",
       "\n",
       "                                    option_value  \\\n",
       "0                                            Yes   \n",
       "1                                             No   \n",
       "2  ! q & t;! q & ! t;t & !q;cycle{!t & q;!t & q}   \n",
       "3     q & ! t;q & ! t;cycle{q & t;q & ! t;q & t}   \n",
       "4     q & !t;! q & t;t & !q;cycle{t & !q;t & !q}   \n",
       "5                       q & t;cycle{q & t;q & t}   \n",
       "\n",
       "                        option_misconceptions  \n",
       "0           [MisconceptionCode.OtherImplicit]  \n",
       "1                                          []  \n",
       "2  [MisconceptionCode.BadStateQuantification]  \n",
       "3           [MisconceptionCode.OtherImplicit]  \n",
       "4               [MisconceptionCode.ImplicitG]  \n",
       "5                                          []  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_options(raw_options):\n",
    "    \"\"\"Parse the question_options JSON string into a list of dicts.\n",
    "    Each dict has keys 'value' and 'misconceptions' (list of strings).\n",
    "    \"\"\"\n",
    "    if pd.isna(raw_options):\n",
    "        return []\n",
    "    try:\n",
    "        options = json.loads(raw_options)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return []\n",
    "\n",
    "    result = []\n",
    "    for opt in options:\n",
    "        value = opt.get('value', '')\n",
    "        misc_raw = opt.get('misconceptions', '[]')\n",
    "        # misconceptions is stored as a Python-list string: \"['MisconceptionCode.Foo']\"\n",
    "        if isinstance(misc_raw, str):\n",
    "            try:\n",
    "                misc_list = ast.literal_eval(misc_raw)\n",
    "            except (ValueError, SyntaxError):\n",
    "                misc_list = []\n",
    "        elif isinstance(misc_raw, list):\n",
    "            misc_list = misc_raw\n",
    "        else:\n",
    "            misc_list = []\n",
    "        result.append({'option_value': value, 'option_misconceptions': misc_list})\n",
    "    return result\n",
    "\n",
    "\n",
    "# Expand each question row into one row per option\n",
    "records = []\n",
    "for _, row in df_raw.iterrows():\n",
    "    options = parse_options(row['question_options'])\n",
    "    if not options:\n",
    "        # Keep a single row even if options couldn't be parsed\n",
    "        rec = row.to_dict()\n",
    "        rec['option_value'] = None\n",
    "        rec['option_misconceptions'] = []\n",
    "        records.append(rec)\n",
    "        continue\n",
    "    for opt in options:\n",
    "        rec = row.to_dict()\n",
    "        rec['option_value'] = opt['option_value']\n",
    "        rec['option_misconceptions'] = opt['option_misconceptions']\n",
    "        records.append(rec)\n",
    "\n",
    "df = pd.DataFrame(records).reset_index(drop=True)\n",
    "print(f\"Expanded to {len(df):,} rows (one per option)\")\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deafdeb",
   "metadata": {},
   "source": [
    "## 3. Extract seed formula per question\n",
    "\n",
    "- **`english_to_ltl`**: seed = the option whose `misconceptions` list is empty (the correct LTL answer).\n",
    "- **`trace_satisfaction_yn`**: `question_text` = `\"<formula>\\n<trace>\"` — take the first line.\n",
    "- **`trace_satisfaction_mc`**: `question_text` is the bare LTL formula.  \n",
    "  As a fallback we also check whether any option value looks like an LTL formula (not a trace) — a value is treated as a trace if it contains `;` or `cycle{`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31dc8558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed formula extraction results (null count per question type):\n",
      "question_type\n",
      "english_to_ltl           0\n",
      "trace_satisfaction_mc    0\n",
      "trace_satisfaction_yn    0\n",
      "Name: seed_formula_raw, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def looks_like_trace(value: str) -> bool:\n",
    "    \"\"\"Return True if value looks like a trace (contains ';' or 'cycle{').\"\"\"\n",
    "    return ';' in value or 'cycle{' in value\n",
    "\n",
    "\n",
    "def extract_seed_formula(row) -> str | None:\n",
    "    \"\"\"Extract the raw (un-normalised) seed formula for a question row.\"\"\"\n",
    "    qtype = row['question_type']\n",
    "    options = parse_options(row['question_options'])\n",
    "\n",
    "    if qtype == 'english_to_ltl':\n",
    "        # Seed = the option with no misconceptions attached\n",
    "        for opt in options:\n",
    "            if not opt['option_misconceptions']:\n",
    "                return opt['option_value'].strip()\n",
    "        return None\n",
    "\n",
    "    elif qtype == 'trace_satisfaction_yn':\n",
    "        # question_text = \"<formula>\\n<trace>\" — the formula is the first non-empty line\n",
    "        text = str(row['question_text'])\n",
    "        first_line = text.strip().split('\\n')[0].strip()\n",
    "        if first_line and not looks_like_trace(first_line):\n",
    "            return first_line\n",
    "        return None\n",
    "\n",
    "    elif qtype == 'trace_satisfaction_mc':\n",
    "        # question_text is the LTL formula\n",
    "        text = str(row['question_text']).strip()\n",
    "        if text and not looks_like_trace(text):\n",
    "            return text\n",
    "        # Fallback: look for an option value that is an LTL formula (not a trace)\n",
    "        for opt in options:\n",
    "            v = opt['option_value'].strip()\n",
    "            if v and not looks_like_trace(v):\n",
    "                return v\n",
    "        return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# Compute seed formula on the *original* (un-expanded) rows first, then merge\n",
    "df_raw['seed_formula_raw'] = df_raw.apply(extract_seed_formula, axis=1)\n",
    "print(\"Seed formula extraction results (null count per question type):\")\n",
    "print(df_raw.groupby('question_type')['seed_formula_raw'].apply(lambda s: s.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912282be",
   "metadata": {},
   "source": [
    "## 4. Normalize seed formulas via `parse_ltl_string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4983a700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formulas that failed normalization: 0\n"
     ]
    }
   ],
   "source": [
    "def normalize_ltl(formula_str: str) -> str | None:\n",
    "    \"\"\"Parse an LTL formula string through parse_ltl_string and return the\n",
    "    canonical string representation. Returns None if parsing fails.\n",
    "    \"\"\"\n",
    "    if not formula_str or pd.isna(formula_str):\n",
    "        return None\n",
    "    try:\n",
    "        node = parse_ltl_string(formula_str.strip())\n",
    "        return str(node)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "df_raw['seed_formula'] = df_raw['seed_formula_raw'].apply(normalize_ltl)\n",
    "\n",
    "# Report how many formulas failed to normalize\n",
    "fail_mask = df_raw['seed_formula_raw'].notna() & df_raw['seed_formula'].isna()\n",
    "print(f\"Formulas that failed normalization: {fail_mask.sum()}\")\n",
    "if fail_mask.any():\n",
    "    print(df_raw.loc[fail_mask, ['id', 'question_type', 'seed_formula_raw']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39f1dc",
   "metadata": {},
   "source": [
    "## 5. Compute `chosen_option`\n",
    "\n",
    "For **`english_to_ltl`** and **`trace_satisfaction_mc`**:\n",
    "- `correct_answer == True` → student chose the option with **no** misconceptions.\n",
    "- `correct_answer == False` → student chose the distractor whose `option_misconceptions` list contains the recorded `misconception`.\n",
    "\n",
    "For **`trace_satisfaction_yn`** the options are just \"Yes\"/\"No\", and misconception tagging is asymmetric:\n",
    "- The **correct** choice = the option with no misconceptions (fallback: \"Yes\" if both/neither are tagged).\n",
    "- `correct_answer == True` → student chose the correct option.\n",
    "- `correct_answer == False` → student chose the *other* option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ff68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chosen_option(row) -> str | None:\n",
    "    \"\"\"Return the value of the option the student selected.\"\"\"\n",
    "    options = parse_options(row['question_options'])\n",
    "    if not options:\n",
    "        return None\n",
    "\n",
    "    correct = row['correct_answer']\n",
    "    qtype = row['question_type']\n",
    "\n",
    "    if qtype == 'trace_satisfaction_yn':\n",
    "        # For Y/N questions we can't rely on misconception matching because\n",
    "        # there may be no misconceptions on either option.\n",
    "        # The correct option = no misconceptions; fallback to \"Yes\" if ambiguous.\n",
    "        no_misc = [o for o in options if not o['option_misconceptions']]\n",
    "        if len(no_misc) == 1:\n",
    "            correct_opt = no_misc[0]['option_value'].strip()\n",
    "        else:\n",
    "            # Ambiguous or both tagged — default correct answer is \"Yes\"\n",
    "            correct_opt = next(\n",
    "                (o['option_value'].strip() for o in options if o['option_value'].strip().lower() == 'yes'),\n",
    "                options[0]['option_value'].strip()\n",
    "            )\n",
    "        wrong_opts = [o['option_value'].strip() for o in options if o['option_value'].strip() != correct_opt]\n",
    "        if correct:\n",
    "            return correct_opt\n",
    "        else:\n",
    "            return wrong_opts[0] if wrong_opts else None\n",
    "\n",
    "    else:\n",
    "        # english_to_ltl and trace_satisfaction_mc\n",
    "        if correct:\n",
    "            for opt in options:\n",
    "                if not opt['option_misconceptions']:\n",
    "                    return opt['option_value'].strip()\n",
    "        else:\n",
    "            # Match the recorded misconception to the chosen distractor\n",
    "            recorded_misc = str(row['misconception']).strip() if pd.notna(row['misconception']) else ''\n",
    "            for opt in options:\n",
    "                if any(recorded_misc == m.strip() for m in opt['option_misconceptions']):\n",
    "                    return opt['option_value'].strip()\n",
    "            # Fallback: first option that has any misconception listed\n",
    "            for opt in options:\n",
    "                if opt['option_misconceptions']:\n",
    "                    return opt['option_value'].strip()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "df_raw['chosen_option'] = df_raw.apply(extract_chosen_option, axis=1)\n",
    "\n",
    "print(\"Null chosen_option:\", df_raw['chosen_option'].isna().sum())\n",
    "df_raw[['id', 'question_type', 'correct_answer', 'misconception', 'chosen_option']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c4d129",
   "metadata": {},
   "source": [
    "## 6. Merge derived columns back into the expanded (per-option) DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6429f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The expanded df still has the original column values per row;\n",
    "# merge seed_formula and chosen_option from df_raw by question id\n",
    "derived = df_raw[['id', 'seed_formula_raw', 'seed_formula', 'chosen_option']]\n",
    "df = df.merge(derived, on='id', how='left')\n",
    "\n",
    "# Clean up: drop the raw question_options column (already expanded)\n",
    "# and reorder for clarity\n",
    "COLS_ORDER = [\n",
    "    'id', 'user_id', 'timestamp', 'question_type', 'mp_class', 'exercise', 'course',\n",
    "    'question_text',\n",
    "    'option_value', 'option_misconceptions',\n",
    "    'seed_formula_raw', 'seed_formula',\n",
    "    'chosen_option',\n",
    "    'correct_answer', 'misconception',\n",
    "]\n",
    "df = df[COLS_ORDER]\n",
    "\n",
    "print(f\"Final DataFrame: {len(df):,} rows × {len(df.columns)} columns\")\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90f376",
   "metadata": {},
   "source": [
    "## 7. Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e16223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per question-type: what fraction have a seed formula?\n",
    "seed_coverage = df.drop_duplicates('id').groupby('question_type')['seed_formula'].apply(\n",
    "    lambda s: s.notna().mean()\n",
    ").rename('seed_formula_coverage')\n",
    "print(seed_coverage)\n",
    "\n",
    "print()\n",
    "\n",
    "# Sample of seed formulas per type\n",
    "for qtype, grp in df.drop_duplicates('id').groupby('question_type'):\n",
    "    print(f\"--- {qtype} ---\")\n",
    "    sample = grp[['id', 'seed_formula_raw', 'seed_formula']].dropna(subset=['seed_formula']).head(3)\n",
    "    print(sample.to_string(index=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify chosen_option makes sense\n",
    "print(\"chosen_option null rate:\", df['chosen_option'].isna().mean().round(3))\n",
    "\n",
    "# For correct answers: chosen_option should not be a misconception option\n",
    "correct_rows = df[df['correct_answer'] == True].drop_duplicates('id')\n",
    "# option_misconceptions for chosen_option should be empty on the correct rows\n",
    "# (check a few manually)\n",
    "print(\"\\nSample correct answers with chosen_option:\")\n",
    "print(correct_rows[['id', 'question_type', 'chosen_option']].head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\nSample incorrect answers with chosen_option:\")\n",
    "wrong_rows = df[df['correct_answer'] == False].drop_duplicates('id')\n",
    "print(wrong_rows[['id', 'question_type', 'misconception', 'chosen_option']].head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81988c1",
   "metadata": {},
   "source": [
    "## 8. Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c912a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_CSV = 'ltl-tutor-responses-processed.csv'\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Saved → {OUT_CSV}  ({len(df):,} rows)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-to-ltl-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
